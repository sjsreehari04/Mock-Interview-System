<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Mock Interview Confidence Analyzer</title>
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet"/>
  <style>
    body {
      background-color: #f8f9fa;
      font-family: 'Segoe UI', sans-serif;
    }
    .container {
      margin-top: 40px;
      max-width: 800px;
    }
    #video {
      width: 100%;
      border-radius: 10px;
      box-shadow: 0 0 20px rgba(0,0,0,0.1);
    }
    .confidence-box {
      background: white;
      border-radius: 10px;
      box-shadow: 0 0 10px rgba(0,0,0,0.1);
      padding: 20px;
      margin-top: 20px;
    }
  </style>
</head>
<body>
  <div class="container text-center">
    <h1 class="mb-4">Mock Interview Confidence Analyzer</h1>

    <div class="question-box mt-4">
      <h4 id="question-category" class="text-primary">Introduction</h4>
      <p id="question-text" class="text-muted">Please introduce yourself.</p>
    </div>

    <video id="video" autoplay muted></video>

    <div class="confidence-box mt-4">
      <h4 id="confidence-score">Confidence: N/A</h4>
      <p id="feedback" class="text-muted">Feedback will appear here after analysis.</p>
    </div>

    <div id="speech-result" class="alert alert-info mt-3" style="display: none;"></div>

    <button id="record-btn" class="btn btn-primary mt-3">Start Monitoring Speech</button>
  </div>
<script>
  const questions = [
    { category: "Introduction", text: "Please introduce yourself." },
    { category: "Experience", text: "What are you currently doing?" },
    { category: "Goals", text: "Where do you see yourself in 5 years?" },
    { category: "Strengths", text: "What are your greatest strengths?" },
    { category: "Weaknesses", text: "What is one area you are working to improve?" },
    { category: "Teamwork", text: "Describe a time you worked effectively in a team." },
    { category: "Leadership", text: "Tell me about a time you took the lead on a project." },
    { category: "Challenges", text: "Describe a challenging situation you faced and how you handled it." },
    { category: "Motivation", text: "What motivates you to perform at your best?" },
    { category: "Adaptability", text: "Tell me about a time you had to adapt to a significant change." }
  ];

  let currentQuestionIndex = 0;
  let scoresThisSession = [];  // accumulate scores

  function showNextQuestion() {
    if (currentQuestionIndex >= questions.length) {
      console.log("All questions completed.");
      showFinalSummaryAndRedirect();
      return;
    }
    const q = questions[currentQuestionIndex];
    document.getElementById("question-category").innerText = q.category;
    document.getElementById("question-text").innerText = q.text;
    speakQuestion(q.text);
  }

  async function initWebcam() {
    const video = document.getElementById("video");
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;
      startFrameCapture(video);
    } catch (error) {
      console.error("Webcam access denied or error:", error);
      document.getElementById("feedback").innerText = "Error accessing webcam. Please allow camera permissions.";
    }
  }

  function getCSRFToken() {
    const cookieValue = document.cookie.split("; ").find(row => row.startsWith("csrftoken="));
    return cookieValue ? cookieValue.split("=")[1] : "";
  }

  function startFrameCapture(video) {
    setInterval(() => {
      const canvas = document.createElement("canvas");
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      const ctx = canvas.getContext("2d");
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const frameData = canvas.toDataURL("image/jpeg");

      fetch("/analyze_facial_confidence/", {
        method: "POST",
        headers: { "Content-Type": "application/x-www-form-urlencoded", "X-CSRFToken": getCSRFToken() },
        body: new URLSearchParams({ frame: frameData })
      })
      .then(response => response.json())
      .then(data => {
        if (data.confidence_score !== undefined) {
          document.getElementById("confidence-score").innerText = `Facial Confidence: ${data.confidence_score}%`;
          document.getElementById("feedback").innerText = data.feedback;
        } else if (data.error) {
          document.getElementById("feedback").innerText = data.error;
        }
      })
      .catch(error => {
        console.error("Error analyzing frame:", error);
        document.getElementById("feedback").innerText = "Server error during facial analysis.";
      });
    }, 3000);
  }

  let mediaRecorder;
  let audioChunks = [];
  let audioStream;

  document.getElementById("record-btn").addEventListener("click", () => {
    showNextQuestion();
    startContinuousMonitoring();
    document.getElementById("record-btn").innerText = "Monitoring...";
    document.getElementById("record-btn").disabled = true;
  });

  async function startContinuousMonitoring() {
    try {
      audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      startNewRecordingChunk();
    } catch (err) {
      console.error("Microphone error:", err);
      document.getElementById("feedback").innerText = "Error accessing microphone. Please allow mic permissions.";
    }
  }

  function startNewRecordingChunk() {
    if (currentQuestionIndex >= questions.length) {
      return;
    }
    mediaRecorder = new MediaRecorder(audioStream, { mimeType: 'audio/webm' });
    audioChunks = [];
    mediaRecorder.start();

    mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
    mediaRecorder.onstop = () => sendChunkForAnalysis(audioChunks);

    setTimeout(() => { if (mediaRecorder.state === "recording") mediaRecorder.stop(); }, 5000);
  }

  function sendChunkForAnalysis(chunks) {
  const audioBlob = new Blob(chunks, { type: 'audio/webm' });
  const formData = new FormData();
  const q = questions[currentQuestionIndex];
  formData.append("audio", audioBlob, "response.webm");
  formData.append("question_category", q.category);
  formData.append("question_text", q.text);

  const facialScoreText = document.getElementById("confidence-score").innerText;
  const match = facialScoreText.match(/(\d+(\.\d+)?)/);
  const facialConfidence = match ? match[1] : "0";
  formData.append("facial_confidence", facialConfidence);

  fetch("/analyze_speech_tone/", {
    method: "POST",
    headers: { "X-CSRFToken": getCSRFToken() },
    body: formData
  })
  .then(response => {
    if (!response.ok) throw new Error(`Server responded with status ${response.status}`);
    return response.json();
  })
  .then(data => {
    if (data.transcript !== undefined) {
      const resultText = `Transcript: ${data.transcript}<br>Speech Rate: ${data.speech_rate_wpm} WPM<br>Pitch: ${data.avg_pitch_hz} Hz<br>Combined Confidence: ${data.combined_confidence}%<br>${data.feedback}`;
      showTemporaryResult(resultText);

      scoresThisSession.push({
        speech: data.speech_confidence,
        facial: parseFloat(facialConfidence),
        combined: data.combined_confidence
      });

      setTimeout(() => {
        currentQuestionIndex++;
        if (currentQuestionIndex >= questions.length) {
          showFinalSummaryAndRedirect();  // âœ… display final performance & redirect
        } else {
          showNextQuestion();
          startNewRecordingChunk();
        }
      }, 20000);  // pause before next question or summary
    } else {
      showTemporaryResult(data.error ? `Error: ${data.error}` : `Unexpected response: ${JSON.stringify(data)}`);
      startNewRecordingChunk();
    }
  })
  .catch(err => {
    console.error("Fetch error:", err);
    showTemporaryResult("Server error during speech analysis.");
    startNewRecordingChunk();
  });
}


  function showFinalSummaryAndRedirect() {
    let totalSpeech = 0, totalFacial = 0, totalCombined = 0;
    scoresThisSession.forEach(s => {
      totalSpeech += s.speech;
      totalFacial += s.facial;
      totalCombined += s.combined;
    });
    const avgSpeech = (totalSpeech / scoresThisSession.length).toFixed(1);
    const avgFacial = (totalFacial / scoresThisSession.length).toFixed(1);
    const avgCombined = (totalCombined / scoresThisSession.length).toFixed(1);
    const verdict = avgCombined >= 75 ? "Excellent" : avgCombined >= 50 ? "Good Work" : "Needs Improvement";

    const summaryHTML = `
      <strong>Interview Summary</strong><br><br>
      <div class="text-start">
        <p><strong>Average Speech Confidence:</strong> ${avgSpeech}%</p>
        <p><strong>Average Facial Confidence:</strong> ${avgFacial}%</p>
        <p><strong>Average Combined Confidence:</strong> ${avgCombined}%</p>
        <p><strong>Performance Verdict:</strong> ${verdict}</p>
      </div>
      <p class="mt-3">You will now be redirected to your homepage.</p>`;

    const summaryBox = document.getElementById("speech-result");
    summaryBox.innerHTML = summaryHTML;
    summaryBox.classList.remove("alert-info");
    summaryBox.classList.add("alert-success");
    summaryBox.style.display = "block";

    speakQuestion(`The interview is complete. Your average combined confidence was ${avgCombined} percent. ${verdict}. You will now be redirected to your homepage.`);
    setTimeout(() => window.location.href = "../user", 20000);
  }

  function showTemporaryResult(html) {
    const feedbackBox = document.getElementById("speech-result");
    feedbackBox.innerHTML = html;
    feedbackBox.style.display = "block";
    setTimeout(() => feedbackBox.style.display = "none", 50000);
  }

  function speakQuestion(text) {
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = "en-US";
    utterance.pitch = 1;
    utterance.rate = 1;
    window.speechSynthesis.speak(utterance);
  }

  window.addEventListener("DOMContentLoaded", initWebcam);
</script>


</body>
</html>
